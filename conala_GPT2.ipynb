{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["###DATA UPLOAD"],"metadata":{"id":"Bf2yg6W7FXWS"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VE-PqugVt-o3","outputId":"48d9ad79-d9f5-4d74-bfe6-c649ce7c9236","executionInfo":{"status":"ok","timestamp":1678966189540,"user_tz":0,"elapsed":18668,"user":{"displayName":"Stefan Swandel","userId":"16898443234107591317"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["###INSTALL DEPENDENCIES AND IMPORT LIBRARIES"],"metadata":{"id":"lBWbOaQBFqr4"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AcH7Qv_uSqZE","outputId":"9db5f484-382f-422f-fd86-780456c3d421","executionInfo":{"status":"ok","timestamp":1678966201047,"user_tz":0,"elapsed":11512,"user":{"displayName":"Stefan Swandel","userId":"16898443234107591317"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.1-py3-none-any.whl (6.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.2-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m836.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.2 tokenizers-0.13.2 transformers-4.27.1\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, random_split\n","from transformers import GPT2Tokenizer, TrainingArguments, Trainer, GPT2LMHeadModel\n","torch.cuda.empty_cache()"],"metadata":{"id":"QRYJtRQXRb1d","executionInfo":{"status":"ok","timestamp":1678966210404,"user_tz":0,"elapsed":9359,"user":{"displayName":"Stefan Swandel","userId":"16898443234107591317"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["PREPARE DATA\n"],"metadata":{"id":"yf3Vu77-TCrd"}},{"cell_type":"code","source":["# ## regular data\n","# df = pd.read_csv('/content/drive/MyDrive/coNaLa-data/conala_alltrain.csv')\n","\n","# # put in form we desire\n","# df = df['intent'] + ' = '  + df['snippet']\n","\n","# # get number of sampels we wish to use\n","# df = df.iloc[0:20000]"],"metadata":{"id":"5nFyrW7UXdy4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## high quality data\n","train_df = pd.read_csv('/content/drive/MyDrive/coNaLa-data/hq_train_gpt2.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/coNaLa-data/hq_test_gpt2.csv')\n","val_df = pd.read_csv('/content/drive/MyDrive/coNaLa-data/hq_val_gpt2.csv')"],"metadata":{"id":"Rbepjq-VL1wq","executionInfo":{"status":"ok","timestamp":1678966211884,"user_tz":0,"elapsed":1485,"user":{"displayName":"Stefan Swandel","userId":"16898443234107591317"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["###TOKENIZER AND MODEL"],"metadata":{"id":"SAUt9TtyRkaJ"}},{"cell_type":"code","source":["tokenizer = GPT2Tokenizer.from_pretrained('gpt2',  bos_token='<|startoftext|>',  eos_token='<|endoftext|>', pad_token='<|pad|>')\n","#model = GPT2LMHeadModel.from_pretrained('gpt2').cuda()\n","model = GPT2LMHeadModel.from_pretrained('/content/drive/MyDrive/fineTunedGPT2_hq').cuda() # continue training\n","model.resize_token_embeddings(len(tokenizer))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x-_--6sERpbO","outputId":"89441258-1e74-4276-dfb6-5ecfb6252d85","executionInfo":{"status":"ok","timestamp":1678966712732,"user_tz":0,"elapsed":2993,"user":{"displayName":"Stefan Swandel","userId":"16898443234107591317"}}},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"execute_result","data":{"text/plain":["Embedding(50259, 768)"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["###PREPARE DATA PART 2"],"metadata":{"id":"GnHTDRarRqGD"}},{"cell_type":"code","source":["max_length = max([len(tokenizer.encode(conala)) for conala in train_df['0']])"],"metadata":{"id":"-PmHJP9vTPM1","executionInfo":{"status":"ok","timestamp":1678966723751,"user_tz":0,"elapsed":7667,"user":{"displayName":"Stefan Swandel","userId":"16898443234107591317"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["class coNaLaDataset(Dataset):\n","    def __init__(self, data, tokenizer, max_length):\n","        self.input_ids = []\n","        self.attn_masks = []\n","        self.labels = []\n","        for i in data['0']:\n","            encodings_dict = tokenizer('<|startoftext|>' + i + '<|endoftext|>', truncation=True,\n","                                       max_length=max_length, padding=\"max_length\")\n","            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n","            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        return self.input_ids[idx], self.attn_masks[idx]"],"metadata":{"id":"d15kUJcWT1Pe","executionInfo":{"status":"ok","timestamp":1678966723751,"user_tz":0,"elapsed":4,"user":{"displayName":"Stefan Swandel","userId":"16898443234107591317"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["train_dataset = coNaLaDataset(train_df, tokenizer, max_length=max_length)\n","val_dataset = coNaLaDataset(val_df, tokenizer, max_length=max_length)"],"metadata":{"id":"EHW--w7HU0Np","executionInfo":{"status":"ok","timestamp":1678966732724,"user_tz":0,"elapsed":8976,"user":{"displayName":"Stefan Swandel","userId":"16898443234107591317"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["my_data_collator = lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n","                                                              'attention_mask': torch.stack([f[1] for f in data]),\n","                                                              'labels': torch.stack([f[0] for f in data])}"],"metadata":{"id":"4bd3w0QFWbgu","executionInfo":{"status":"ok","timestamp":1678966732725,"user_tz":0,"elapsed":20,"user":{"displayName":"Stefan Swandel","userId":"16898443234107591317"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir='/content/drive/MyDrive/GPT2-FineTuned',\n","    evaluation_strategy = 'epoch',\n","    save_strategy = 'epoch',\n","    per_device_train_batch_size=2, \n","    per_device_eval_batch_size=2,\n","    num_train_epochs=3, \n","    gradient_accumulation_steps = 5,\n","    warmup_steps=10, \n","    weight_decay=0.05, \n","    report_to = 'none',\n","    save_total_limit = 2,\n","    load_best_model_at_end = True,\n","    )\n","\n","\n","trainer = Trainer(\n","    model = model,\n","    args = training_args,\n","    train_dataset = train_dataset,\n","    eval_dataset = val_dataset,\n","    data_collator = my_data_collator\n",")\n","\n","trainer.train()\n","\n","trainer.save_model('/content/drive/MyDrive/fineTunedGPT2_hq')\n","trainer.save_state()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":225},"id":"Ayyw2Za6VbFQ","outputId":"42036d13-909e-4ca6-c961-d4608b38b10b","executionInfo":{"status":"ok","timestamp":1678975802321,"user_tz":0,"elapsed":9069615,"user":{"displayName":"Stefan Swandel","userId":"16898443234107591317"}}},"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='7404' max='7404' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [7404/7404 2:31:04, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.125300</td>\n","      <td>0.129454</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.108100</td>\n","      <td>0.118961</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.104300</td>\n","      <td>0.115103</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"markdown","source":["###GENERATED DESCRIPTION"],"metadata":{"id":"cZ1GjyvkY2rR"}},{"cell_type":"code","source":["# define the tokenizer and load the trained model\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2',  bos_token='<|startoftext|>',  eos_token='<|endoftext|>', pad_token='<|pad|>')\n","model = GPT2LMHeadModel.from_pretrained('/content/drive/MyDrive/fineTunedGPT2_hq').cuda() # continue training\n","model.resize_token_embeddings(len(tokenizer))"],"metadata":{"id":"nV8-YFWzz_Qu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generated = tokenizer(\"<|startoftext|>  get first element of python list = \", return_tensors=\"pt\").input_ids.cuda()"],"metadata":{"id":"3v5RsrhVYxLy","executionInfo":{"status":"ok","timestamp":1678976527942,"user_tz":0,"elapsed":322,"user":{"displayName":"Stefan Swandel","userId":"16898443234107591317"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":["sample_outputs = model.generate(generated, do_sample=True, top_k=50, \n","                                max_length=50, top_p=0.95, temperature=0.1, num_return_sequences=5,\n","                                pad_token_id=tokenizer.encode('<|pad|>')[0])"],"metadata":{"id":"8bWDPUJ0ZeDw","executionInfo":{"status":"ok","timestamp":1678976529812,"user_tz":0,"elapsed":3,"user":{"displayName":"Stefan Swandel","userId":"16898443234107591317"}}},"execution_count":77,"outputs":[]},{"cell_type":"code","source":["for i, sample_output in enumerate(sample_outputs):\n","    print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"],"metadata":{"id":"osD3xK2pZmFB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9ce8f313-36a7-48c2-e121-49aca92fe59f","executionInfo":{"status":"ok","timestamp":1678976531547,"user_tz":0,"elapsed":3,"user":{"displayName":"Stefan Swandel","userId":"16898443234107591317"}}},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["0:   get first element of python list =   a[0]\n","1:   get first element of python list =   a[0]\n","2:   get first element of python list =   a[0]\n","3:   get first element of python list =   a[0]\n","4:   get first element of python list =   a[0]\n"]}]}]}